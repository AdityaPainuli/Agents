{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install langchain_community tiktoken langchain_openai langchainhub chromadb langchain bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
    "os.environ['LANGCHAIN_ENDPOINT'] = 'https://api.smith.langchain.com'\n",
    "os.environ['LANGCHAIN_API_KEY'] = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY'] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "### Indexing ###\n",
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "blog_docs = loader.load()\n",
    "\n",
    "# Split\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=300,\n",
    "    chunk_overlap=50\n",
    ")\n",
    "splits = text_splitter.split_documents(blog_docs)\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "vectorstore = Chroma.from_documents(documents=splits,embedding = OpenAIEmbeddings())\n",
    "\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "template = \"\"\"You are an AI language model assistant. Your task is to generate five \n",
    "different versions of the given user question to retrieve relevant documents from a vector \n",
    "database. By generating multiple perspectives on the user question, your goal is to help\n",
    "the user overcome some of the limitations of the distance-based similarity search. \n",
    "Provide these alternative questions separated by newlines. Original question: {question}\"\"\"\n",
    "prompt_perspectives = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Creating a chain for generating questions out of the questions\n",
    "generate_queries = (\n",
    "    prompt_perspectives \n",
    "    | ChatOpenAI(temperature=0) \n",
    "    | StrOutputParser() \n",
    "    | (lambda x: x.split(\"\\n\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1. How do LLM agents utilize task decomposition in their operations?', '2. Can you explain the concept of task decomposition as applied to LLM agents?', '3. In what ways do LLM agents benefit from task decomposition?', '4. What role does task decomposition play in the functioning of LLM agents?', '5. How is task decomposition integrated into the workflow of LLM agents?']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.load import dumps,loads\n",
    "\n",
    "def get_unique_union(documents:list[list]):\n",
    "    \"\"\"Unique union of retrieved docs\"\"\"\n",
    "    # flatten list of lists , and convert each Document to string\n",
    "    flatten_docs = [dumps(doc) for sublist in documents for doc in sublist]\n",
    "    unique_docs = list(set(flatten_docs))\n",
    "    return [loads(doc) for doc in unique_docs]\n",
    "\n",
    "question = \"What is task decomposition for LLM agents?\"\n",
    "\n",
    "\n",
    "retrieval_chain = generate_queries | retriever.map() | get_unique_union\n",
    "docs = retrieval_chain.invoke({\"question\":question})\n",
    "\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Task decomposition for LLM agents involves breaking down complex tasks into smaller, manageable subgoals. This process enables the agent to efficiently handle and solve complex tasks by dividing them into smaller steps that are easier to tackle. Task decomposition can be achieved through techniques such as Chain of Thought (CoT) and Tree of Thoughts, which prompt the model to think step by step and explore multiple reasoning possibilities at each step, respectively. Additionally, task decomposition can be facilitated by simple prompting from LLM, task-specific instructions, or human inputs.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# Running final rag from all the questions we get \n",
    "template = \"\"\"Answer the following question based on this context:\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "\n",
    "final_rag_chain = (\n",
    "    {\"context\": retrieval_chain, \n",
    "     \"question\": itemgetter(\"question\")} \n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "final_rag_chain.invoke({\"question\":question})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG fusion \n",
    "- Search methodology that aims to bridge gap between traditional search paradigms and multifaceted dimensions of human queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "template = \"\"\"You are a helpful assistant that generates multiple search queries based on a single input query. \\n\n",
    "Generate multiple search queries related to: {question} \\n\n",
    "Output (4 queries):\"\"\"\n",
    "prompt_rag_fusion = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "generate_queries = (\n",
    "    prompt_rag_fusion\n",
    "    | ChatOpenAI(temperature=0)\n",
    "    | StrOutputParser()\n",
    "    | (lambda x: x.split(\"\\n\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.load import dumps, loads\n",
    "\n",
    "def reciprocal_rank_fusion(results: list[list], k=60):\n",
    "    \"\"\"Reciprocal_rank_fusion that takes multiple list of ranked documents and an optional \n",
    "    parameter k used in the RRF formula\"\"\"\n",
    "    fused_scores = {}\n",
    "  \n",
    "    for docs in results:\n",
    "        for rank, doc in enumerate(docs):\n",
    "            doc_str = dumps(doc)\n",
    "            if doc_str not in fused_scores:\n",
    "                fused_scores[doc_str] = 0\n",
    "            previous_score = fused_scores[doc_str]\n",
    "            fused_scores[doc_str] += 1 / (rank + k)\n",
    "    reranked_results = [\n",
    "        (loads(doc), score)\n",
    "        for doc, score in sorted(fused_scores.items(), key= lambda x: x[1], reverse=True)\n",
    "    ]\n",
    "    return reranked_results\n",
    "\n",
    "retrieval_chain_rag_fusion = generate_queries | retriever.map() | reciprocal_rank_fusion\n",
    "docs = retrieval_chain_rag_fusion.invoke({\"question\": question})\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Task decomposition for LLM agents involves breaking down complex tasks into smaller and simpler steps to enhance model performance. This can be achieved through techniques like Chain of Thought (CoT) and Tree of Thoughts, which prompt the model to think step by step and explore multiple reasoning possibilities at each step. Task decomposition can be done through simple prompting, task-specific instructions, or with human inputs.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "template = \"\"\"\"Answe the following question based on this context:\n",
    "{context}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "final_rag_chain = (\n",
    "    {\"context\": retrieval_chain_rag_fusion,\n",
    "     \"question\": itemgetter(\"question\")}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "final_rag_chain.invoke({\"question\":question})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task decomposition\n",
    "- It levarge the approach of dividing question into sub-questions and solving them sequentially.\n",
    "- It also uses chain-of-thought meaning using the solution of solved question to solved the upcoming question to provide better context.\n",
    "- We will use to answer recursively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "template = \"\"\"You are a helpful assistant that generates multiple sub-questions related to an input question. \\n\n",
    "The goal is to break down the input into a set of sub-problems / sub-questions that can be answers in isolation. \\n\n",
    "Generate multiple search queries related to: {question} \\n\n",
    "Output (3 queries):\"\"\"\n",
    "prompt_decomposition = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "generate_queries_decomposition = (prompt_decomposition | llm | StrOutputParser() | (lambda x: x.split(\"\\n\")))\n",
    "\n",
    "question = \"What are the main components of an LLM-powered autnomous agent system?\"\n",
    "questions = generate_queries_decomposition.invoke({\"question\":question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1. What is LLM technology and how does it work in autonomous agent systems?',\n",
       " '2. What are the specific components that make up an LLM-powered autonomous agent system?',\n",
       " '3. How do the main components of an LLM-powered autonomous agent system interact with each other to enable autonomous behavior?']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We have divided the problem into 3 sub-questions and now we will solve them recursively "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "template = \"\"\"Here is the question you need to answer:\n",
    "\n",
    "\\n --- \\n {question} \\n --- \\n\n",
    "\n",
    "Here is any available background question + answer pairs:\n",
    "\n",
    "\\n --- \\n {q_a_pairs} \\n --- \\n\n",
    "\n",
    "Here is additional context relevant to the question: \n",
    "\n",
    "\\n --- \\n {context} \\n --- \\n\n",
    "\n",
    "Use the above context and any background question + answer pairs to answer the question: \\n {question}\n",
    "\"\"\"\n",
    "\n",
    "decomposition_prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here we are ussing runnablePassThrough from langchain to answer each sub-question and eachtime send past question_and_answer pairs for better context . \n",
    "- In the end , we get the last final question answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: 1. What is LLM technology and how does it work in autonomous agent systems?\n",
      "Answer: LLM technology, which stands for Large Language Model, is utilized in autonomous agent systems as the core controller. In these systems, LLM functions as the agent's brain and is complemented by key components such as planning, subgoal decomposition, reflection, and refinement. LLM-powered autonomous agents break down large tasks into smaller subgoals to efficiently handle complex tasks. They can also engage in self-criticism and self-reflection to learn from past actions, refine their strategies, and improve the quality of their final results. Additionally, LLM technology can be integrated with external classical planners to facilitate long-horizon planning in certain setups. Overall, LLM technology in autonomous agent systems enables agents to solve problems, interact with the environment, and continuously improve through self-reflection and planning mechanisms.\n",
      "Question: 2. What are the specific components that make up an LLM-powered autonomous agent system?\n",
      "Answer: The specific components that make up an LLM-powered autonomous agent system include:\n",
      "\n",
      "1. Planning: This involves breaking down large tasks into smaller, manageable subgoals to efficiently handle complex tasks. Techniques like Chain of Thought (CoT) and Tree of Thoughts are used to decompose tasks into simpler steps.\n",
      "\n",
      "2. Subgoal Decomposition: Agents utilize prompts to decompose tasks into manageable subgoals, enabling them to tackle complex tasks effectively.\n",
      "\n",
      "3. Reflection and Refinement: Autonomous agents engage in self-criticism and self-reflection over past actions, learning from mistakes and refining their strategies for future steps to improve the quality of their final results.\n",
      "\n",
      "4. External Classical Planner Integration: In some setups, LLM-powered agents may rely on an external classical planner for long-horizon planning. This involves translating the problem into a Planning Domain Definition Language (PDDL) and utilizing a classical planner to generate a plan, which is then translated back into natural language.\n",
      "\n",
      "5. Self-Reflection Mechanisms: Self-reflection is crucial for autonomous agents to iteratively improve by refining past action decisions and correcting mistakes. Systems like ReAct integrate reasoning and acting within LLM, expanding the action space to include task-specific actions and language prompts for generating reasoning traces in natural language.\n",
      "Question: 3. How do the main components of an LLM-powered autonomous agent system interact with each other to enable autonomous behavior?\n",
      "Answer: The main components of an LLM-powered autonomous agent system interact with each other in a coordinated manner to enable autonomous behavior. \n",
      "\n",
      "1. Planning: The agent utilizes techniques like Chain of Thought (CoT) and Tree of Thoughts to decompose complex tasks into smaller subgoals. This planning process helps the agent understand the steps involved in a task and plan ahead.\n",
      "\n",
      "2. Subgoal Decomposition: By breaking down tasks into manageable subgoals, the agent can efficiently handle complex tasks. This component enables the agent to focus on smaller, achievable steps towards achieving the overall goal.\n",
      "\n",
      "3. Reflection and Refinement: Autonomous agents engage in self-criticism and self-reflection over past actions, learning from mistakes, and refining their strategies for future steps. This continuous improvement process enhances the quality of the agent's final results.\n",
      "\n",
      "4. External Classical Planner Integration: In certain setups, the agent may rely on an external classical planner for long-horizon planning. This integration involves translating the problem into a Planning Domain Definition Language (PDDL), generating a plan, and translating it back into natural language. This collaboration enhances the agent's ability to plan and execute tasks effectively.\n",
      "\n",
      "5. Self-Reflection Mechanisms: Self-reflection is crucial for autonomous agents to iteratively improve by refining past action decisions and correcting mistakes. Systems like ReAct integrate reasoning and acting within LLM, expanding the action space to include task-specific actions and language prompts for generating reasoning traces in natural language. This self-reflection mechanism enhances the agent's learning and decision-making capabilities. \n",
      "\n",
      "Overall, the interaction between these components allows the LLM-powered autonomous agent system to effectively plan, execute tasks, learn from experiences, and continuously improve its performance, enabling autonomous behavior.\n"
     ]
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "def format_qa_pair(question, answer):\n",
    "    \"\"\"Format Q and A pair\"\"\"\n",
    "    \n",
    "    formatted_string = \"\"\n",
    "    formatted_string += f\"Question: {question}\\nAnswer: {answer}\\n\\n\"\n",
    "    return formatted_string.strip()\n",
    "\n",
    "# llm\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "q_a_pairs = \"\"\n",
    "for q in questions:\n",
    "    \n",
    "    rag_chain = (\n",
    "    {\"context\": itemgetter(\"question\") | retriever, \n",
    "     \"question\": itemgetter(\"question\"),\n",
    "     \"q_a_pairs\": itemgetter(\"q_a_pairs\")} \n",
    "    | decomposition_prompt\n",
    "    | llm\n",
    "    | StrOutputParser())\n",
    "\n",
    "    answer = rag_chain.invoke({\"question\":q,\"q_a_pairs\":q_a_pairs})\n",
    "    q_a_pair = format_qa_pair(q,answer)\n",
    "    q_a_pairs = q_a_pairs + \"\\n---\\n\"+  q_a_pair\n",
    "    print(q_a_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The main components of an LLM-powered autonomous agent system interact with each other in a coordinated manner to enable autonomous behavior. \\n\\n1. Planning: The agent utilizes planning to break down large tasks into smaller, manageable subgoals. This involves techniques like Task Decomposition using prompts or task-specific instructions. Planning sets the roadmap for the agent's actions and guides it towards achieving its goals.\\n\\n2. Subgoal Decomposition: Once the tasks are broken down into smaller steps, the agent engages in subgoal decomposition to transform complex tasks into multiple manageable tasks. Techniques like Chain of Thought (CoT) and Tree of Thoughts help in this process by exploring multiple reasoning possibilities at each step. This step ensures that the agent can handle intricate tasks effectively.\\n\\n3. Reflection and Refinement: The agent engages in self-criticism and self-reflection over past actions to learn from mistakes and refine them for future steps. By reflecting on its actions, the agent can improve the quality of its final results and enhance its decision-making process.\\n\\n4. External Classical Planner Integration: In certain setups, the agent can rely on an external classical planner for long-horizon planning. This involves translating the problem into a Planning Domain Definition Language (PDDL), generating a PDDL plan, and translating it back into natural language. This integration enhances the agent's ability to plan and execute complex tasks efficiently.\\n\\n5. Self-Reflection Integration: Autonomous agents can improve iteratively by refining past action decisions and correcting mistakes through self-reflection. Techniques like ReAct integrate reasoning and acting within LLM, allowing the agent to generate reasoning traces in natural language and enhance its interaction with the environment.\\n\\nOverall, the interaction between these components enables the LLM-powered autonomous agent system to autonomously handle tasks, learn from its experiences, and continuously improve its performance.\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-back prompting -\n",
    "- Step-back prompting uses technique quite opposite of what other query translation we have seen till now . \n",
    "- Based on a normal question it create some abstract question to get a broader view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate , FewShotChatMessagePromptTemplate\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"input\": \"Could the members of The Police perform lawful arrests?\",\n",
    "        \"output\": \"what can the members of The Police do?\",\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"Jan Sindel’s was born in what country?\",\n",
    "        \"output\": \"what is Jan Sindel’s personal history?\",\n",
    "    },\n",
    "]\n",
    "\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\",\"{input}\"),\n",
    "        (\"ai\",\"{output}\")\n",
    "    ]\n",
    ")\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(example_prompt=example_prompt,examples=examples)\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"You are an expect at world knowledge. You task is to step back and paraphrase a question a more generic step-back questions,\n",
    "            which is easier to answer. Here are a few examples:\"\"\",\n",
    "        ),\n",
    "        few_shot_prompt,\n",
    "        (\"user\",\"{question}\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is involved in breaking down tasks for LLM agents?'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_queries_step_back = prompt | ChatOpenAI(temperature=0) | StrOutputParser()\n",
    "question = \"What is task decomposition for LLM agents?\"\n",
    "generate_queries_step_back.invoke({\"question\":question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Task decomposition for LLM agents refers to the process of breaking down complex tasks into smaller, more manageable subgoals or steps. This approach allows the agent to efficiently handle intricate tasks by dividing them into simpler components. Task decomposition is essential for LLM-powered autonomous agents as it enables them to plan ahead and navigate through various stages of a task systematically.\\n\\nIn the context of LLM agents, task decomposition can be achieved through various techniques such as Chain of Thought (CoT) and Tree of Thoughts. CoT involves prompting the model to \"think step by step\" and decompose hard tasks into smaller and simpler steps. This technique transforms big tasks into multiple manageable tasks and provides insights into the model\\'s thinking process. On the other hand, Tree of Thoughts extends CoT by exploring multiple reasoning possibilities at each step, creating a tree structure of thought steps and generating multiple thoughts per step.\\n\\nTask decomposition can be facilitated by providing simple prompts to the LLM, such as \"Steps for XYZ\" or \"What are the subgoals for achieving XYZ?\" Alternatively, task-specific instructions can be used, like \"Write a story outline\" for writing a novel. Human inputs can also be utilized for task decomposition, allowing for a more interactive and collaborative approach to breaking down tasks.\\n\\nOverall, task decomposition plays a crucial role in enhancing the performance of LLM agents by enabling them to tackle complex tasks effectively through a structured and organized approach. By breaking down tasks into smaller subgoals, LLM agents can navigate through intricate problems with greater ease and efficiency, ultimately leading to improved task completion and problem-solving capabilities.'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough , RunnableLambda\n",
    "response_prompt_template = \"\"\"You are an expert of world knowledge. I am going to ask you a question. Your response should be comprehensive and not contradicted with the following context if they are relevant. Otherwise, ignore them if they are not relevant.\n",
    "\n",
    "# {normal_context}\n",
    "# {step_back_context}\n",
    "\n",
    "# Original Question: {question}\n",
    "# Answer:\"\"\"\n",
    "response_prompt = ChatPromptTemplate.from_template(response_prompt_template)\n",
    "\n",
    "chain = (\n",
    "    {\n",
    "        # Retrieve context using the normal question\n",
    "        \"normal_context\": RunnableLambda(lambda x: x[\"question\"]) | retriever,\n",
    "        # Retrieve context using the step-back question\n",
    "        \"step_back_context\": generate_queries_step_back | retriever,\n",
    "        # Pass on the question\n",
    "        \"question\": lambda x: x[\"question\"],\n",
    "    }\n",
    "    | response_prompt\n",
    "    | ChatOpenAI(temperature=0)\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "chain.invoke({\"question\": question})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
